---
title: Linear Spaces
categories: Linear Algebra
icon: /img/icons/vector-spaces.png
...

<section class="primary">

# Summary

<div class="block">

![Subspace Example](/img/diagrams/linear/subspaces.png)

A **linear space** $V$ is a set endowed with a rule for addition (if $f$ and $g$ are in $V$, then so is
$f + g$) and a rule for scalar multiplication (if $f$ is in $V$ and $k$ in $\bbr$, then $kf$ is in
$V$) such that these operations satisfy the following eight rules (for all $f, g, h$ in $V$ and all
$c, k$ in $\bbr$):

1. $(f + g) + h = f+ (g + h)$.
2. $f + g = g + f$.
3. There exists a **neutral element $n$** in $V$ such that $f + n = f$, for all
   $f$ in $V$. This $n$ is unique and denoted by $0$.
4. For each $f$ in $V$ there exists a $g$ in $V$ such that $f + g = 0$. This
   $g$ is unique and denoted by $(-f)$.
5. $k(f + g) = kf + kg$.
6. $(c + k)f = cf + kf$.
7. $c(kf) = (ck)f$.
8. $1f = f$.

</div>

</section>

<section class="primary">

# Isomorphisms

An invertible linear transformation $T$ is called an **isomorphism**. We say that the linear space $V$
is isomorphic to the linear space $W$ if there exists an isomorphism $T$ from $V$ to $W$.

<section class="secondary">

## Properties 

For parts (2)-(5), assume $V$ and $W$ are finite dimensional.

1. A linear transformation $T$ from $V$ to $W$ is an isomorphism if and only if
   $\text{ker}(T) = \{\vec{0}\}$ and $\text{im}(T) = W$.<br />  
   <div class="proof">
   $\forward$ Suppose that $T$ is an isomorphism. To find the kernel of $T$, we have to solve the equation
   $T(f)=\vec{0}$. Applying $T^{-1}$ on both sides, we find that 
   $$ f = T^{-1}(\vec{0}) = \vec{0} \Rightarrow \text{ker(T)} = \{\vec{0}\}\text{,} $$
   as claimed. To see that $\text{im}(T) = W$, note that any $g$ in $V$ can be written as $g=T(T^{-1}(g))$.  
   $\backward$ Suppose that $\text{ker}(T) = \{\vec{0}\}$ and $\text{im}(T)=W$. We have to show that $T$ is
   invertible; that is, the equation $T(f) = g$ has a unique solution $f$ for every $g$ in $W$. There is at least one 
   solution $f$ since $\text{im}(T) = W$. Consider two solutions $f_1$ and $f_2$, so that $T(f_1) = T(f_2) = g$. Then 
   $$ \vec{0} = T(f_1) - T(f_2) = T(f_1-f_2)\text{,} $$ 
   so that $f_1-f_2$ is in the kernel of $T$. Since the kernel of $T$ is $\{\vec{0}\}$, we must have 
   $f_1 - f_2 = \vec{0}$ and $f_1=f_2$, as claimed.
   </div><br />

2. If $V$ is isomorphic to $W$, then $\text{dim}(V) = \text{dim}(W)$.<br />  
   <div class="proof">
   By part (1), $\text{ker}(T) = \{\vec{0}\}$ and $\text{im}(T) = W$. Thus, by the [Rank-Nullity Theorem](rank_nullity_theorem), 
   $$ \text{dim}(V) = \text{dim}(\text{ker}\;T) + \text{dim}(\text{im}\;T) = 0 + \text{dim}(W) = \text{dim}(W)\text{.} $$
   </div><br />

3. Suppose $T$ is a linear transformation from $V$ to $W$ with $\text{ker}(T) = \{\vec{0}\}$. If 
   $\text{dim}(V) = \text{dim}(W)$, then $T$ is an isomorphism.<br />  
   <div class="proof">
   By part (1), it suffices to show that $\text{im}(T)=W$, or, equivalently, that
   $\text{dim}(\text{im}\;T) = \text{dim}(W)$. By the Rank-Nullity Theorem, 
   $$ 
     \text{dim}(W) = \text{dim}(V) = \text{dim}(\text{ker}\;T) + \text{dim}(\text{im}\;T) 
                   = \text{dim}(\text{im}(T))\text{.}
   $$
   </div><br />
   
4. Suppose $T$ is a linear transformation from $V$ to $W$ with $\text{im}(T) = W$.
   If $\text{dim}(V) = \text{dim}(W)$, then $T$ is an isomorphism.<br />  
   <div class="proof">
   By part (1), it suffices to show that $\text{ker}(T) = \{\vec{0}\}$, or, equivalently,
   that $\text{dim}(\text{ker}\;T) = 0$. By the Rank-Nullity Theorem, 
   $$ 
     \text{dim}(W) = \text{dim}(V) = \text{dim}(\text{ker}\;T) + \text{dim}(\text{im}\;T) 
                   = \text{dim}(\text{ker}\;T) + \text{dim}(W)\text{.}
   $$
   </div><br />

5. Suppose $T$ is an isomorphism from $V$ to $W$. If $(\inflate{\;f}{n})$ is a basis of $V$, then 
   $(T(f_1), T(f_2), \ldots, T(f_n))$ is a basis of $W$.<br />  
   <div class="proof">
   First notice that for any $g$ in $W$, there exists $T^{-1}(g)$ in $V$, so we can write
   $$ T^{-1}(g) = c_1f_1 + c_2f_2 + \cdots + c_nf_n $$
   because $f_i$ span $V$. Applying $T$ on both sides
   $$ g = c_1T(f_1) + c_2T(f_2) + \cdots + c_nT(f_n). $$
   Next, consider a relation
   $$ c_1T(f_1) + c_2T(f_2) + \cdots + c_nT(f_n) = \vec{0} $$
   or 
   $$ T(c_1f_1 + c_2f_2 + \cdots + c_nf_n) = \vec{0}. $$
   Since $\text{ker}(T)$ is $\{\vec{0}\}$, we have
   $$ c_1f_1 + c_2f_2 + \cdots + c_nf_n = \vec{0}. $$
   Since each $f_i$ is linearly independent, the $c_i$ must be all zero.
   Therefore $T(f_n)$ are linearly independent and span $W$, so it must be a basis.
   </div>

</section>

<section class="secondary">

## Coordinate Transformations

If $\beta = (\inflate{\;f}{n})$ is a basis of a linear space $V$, then the **coordinate transformation**
$$ L_{\beta}(f) = \bcoor{f} = \begin{bmatrix} c_1 \\ \vdots \\ c_n \end{bmatrix} \text{ from } V \text{ to } \bbr^n $$
is an isomorphism. Thus $V$ is isomorphic to $\bbr^n$; the spaces $V$ and $\bbr^n$ have the same structure. Therefore, 
all techniques applied to vector spaces also apply to finite dimensional linear spaces.

</section>

</section>

<section class="primary">

# Notes

- Bretscher, Otto (2008). Linear Algebra with Applications (4th ed.). Pearson. ISBN 978-0-13-600926-9.

</section>
